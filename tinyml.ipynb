{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import time\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from sklearn.metrics import  f1_score, precision_score, recall_score, jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU não disponível\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU disponível\")\n",
    "else:\n",
    "    print(\"GPU não disponível\")\n",
    "\n",
    "# Aloca memória de forma dinâmica para a GPU\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "\n",
    "# Caso queira controlar a quantidade de memória alocada, use:\n",
    "# tf.config.set_virtual_device_configuration(gpu_devices[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    # Ensure the tensors are of type float32\n",
    "    y_true_f = K.cast(K.flatten(y_true), 'float32')\n",
    "    y_pred_f = K.cast(K.flatten(y_pred), 'float32')\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "  return iou\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + 0.5 * dice_loss(tf.cast(y_true, tf.float32), y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\ProjetoFeridas\\segmentacao\\image-seg-wounds\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#carrega o modelo\n",
    "model = tf.keras.models.load_model('models/1final_model_unetoriginal.keras', custom_objects={'bce_dice_loss': bce_dice_loss, 'dice_coef': dice_coef}, safe_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\joaod\\AppData\\Local\\Temp\\tmpcnunyhqf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\joaod\\AppData\\Local\\Temp\\tmpcnunyhqf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\joaod\\AppData\\Local\\Temp\\tmpcnunyhqf'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2375008312144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008311760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008311952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008312336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008312528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008309840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008313872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008313104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008314832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008313296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008315984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008315216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008316944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008315792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008317712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008316560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008318864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008318096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008320016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008319248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008318672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008320784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008321360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008319632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009403152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009403536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009403344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009404496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009405648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009403728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009406416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009405264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009403920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009406800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009407952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009405456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009408720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009407568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009406224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009409104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009410256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009407760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009411024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009409872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009408528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009411408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open('TinyML/tflite', 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\joaod\\AppData\\Local\\Temp\\tmpnk5rd_ff\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\joaod\\AppData\\Local\\Temp\\tmpnk5rd_ff\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\joaod\\AppData\\Local\\Temp\\tmpnk5rd_ff'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2375008312144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008311760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008311952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008312336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008312528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008309840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008313872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008313104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008314832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008313296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008315984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008315216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008316944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008315792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008317712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008316560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008318864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008318096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008320016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008319248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008318672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008320784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008321360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375008319632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009403152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009403536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009403344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009404496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009405648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009403728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009406416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009405264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009403920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009406800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009407952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009405456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009408720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009407568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009406224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009409104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009410256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009407760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009411024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009409872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009408528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2375009411408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_qaware_model = converter.convert()\n",
    "with open('TinyML/tflite-reduzido', 'wb') as f:\n",
    "    f.write(tflite_qaware_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "VAL_PATH = 'data_mod/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(input_image, input_mask):\n",
    "    input_image = tf.image.resize(input_image, (IMG_WIDTH, IMG_HEIGHT), method=\"nearest\")\n",
    "    input_mask = tf.image.resize(input_mask, (IMG_WIDTH, IMG_HEIGHT), method=\"nearest\")\n",
    "    # Convert mask to grayscale\n",
    "    input_mask = tf.image.rgb_to_grayscale(input_mask)\n",
    "\n",
    "    return input_image, input_mask \n",
    "\n",
    "def normalize(input_image):\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    input_image = input_image / 255.0\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:07<00:00, 24.46it/s]\n"
     ]
    }
   ],
   "source": [
    "VAL_PATH = 'data_mod/validation/'\n",
    "\n",
    "n_val = len(os.listdir(VAL_PATH+'images'))\n",
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "# Load val images\n",
    "# Load train images\n",
    "for i in tqdm(range(n_val)):\n",
    "    # Carrega a imagem e a máscara\n",
    "    img = imread(VAL_PATH+'images/'+os.listdir(VAL_PATH+'images')[i])[:,:,:IMG_CHANNELS]\n",
    "    mask = imread(VAL_PATH+'labels/'+os.listdir(VAL_PATH+'labels')[i])\n",
    "    img, mask = resize(img, mask)\n",
    "    img = normalize(img)\n",
    "    mask = normalize(mask)\n",
    "    X_val.append(img)\n",
    "    Y_val.append(mask)\n",
    "    \n",
    "    # Faz a augmentação e adiciona a imagem flipada, se houver\n",
    "    # img, mask, is_flip = augment(img, mask)\n",
    "    # if is_flip:\n",
    "    #     X_val.append(img)\n",
    "    #     Y_val.append(mask)\n",
    "\n",
    "# Converter listas para arrays NumPy\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "Y_val = (Y_val > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(preds_threshold):\n",
    "    dice_values = []\n",
    "    for ix in range(len(Y_val)):\n",
    "        dice_value = dice_coef(Y_val[ix].flatten(), preds_threshold[ix].flatten()).numpy()  \n",
    "        dice_values.append(dice_value)\n",
    "\n",
    "    dice_mean = np.mean(dice_values)\n",
    "\n",
    "\n",
    "\n",
    "    f1_values = []\n",
    "    for ix in range(len(Y_val)):\n",
    "        f1_value = f1_score(Y_val[ix].flatten(), preds_threshold[ix].flatten(), zero_division=0)\n",
    "        f1_values.append(f1_value)\n",
    "\n",
    "    f1_mean = np.mean(f1_values)    \n",
    "\n",
    "    precision_values = []\n",
    "    for ix in range(len(Y_val)):\n",
    "        precision_value = precision_score(Y_val[ix].flatten(), preds_threshold[ix].flatten(), zero_division=0)\n",
    "        precision_values.append(precision_value)\n",
    "\n",
    "    precision_mean = np.mean(precision_values)\n",
    "\n",
    "    recall_values = []\n",
    "    for ix in range(len(Y_val)):\n",
    "        recall_value = recall_score(Y_val[ix].flatten(), preds_threshold[ix].flatten(), zero_division=0)\n",
    "        recall_values.append(recall_value)\n",
    "\n",
    "    recall_mean = np.mean(recall_values)\n",
    "\n",
    "    iou_values = []\n",
    "    for ix in range(len(Y_val)):\n",
    "        iou_value = jaccard_score(Y_val[ix].flatten(), preds_threshold[ix].flatten())\n",
    "        iou_values.append(iou_value)\n",
    "\n",
    "    iou_mean = np.mean(iou_values)\n",
    "\n",
    "    return dice_mean, f1_mean, precision_mean, recall_mean, iou_mean\n",
    "\n",
    "def tinyML(model_path):\n",
    "    gpu_delegate = tf.lite.experimental.load_delegate('TinyML/libtensorflowlite_gpu_delegate.so')\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path, experimental_delegates=[gpu_delegate])\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    input_shape = input_details[0]['shape']\n",
    "    output_shape = output_details[0]['shape']\n",
    "\n",
    "    preds = []\n",
    "    start_time = time.time()\n",
    "    for i in range(n_val):\n",
    "        input_tensor = X_val[i].reshape(input_shape)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        preds.append(output_data)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    preds_threshold = (preds > 0.3).astype(np.uint8)\n",
    "\n",
    "    model_size = os.path.getsize(model_path) / (1024 * 1024)\n",
    "    eval_values = evaluate(preds_threshold)\n",
    "    return model_path, model_size, inference_time, eval_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 193] %1 não é um aplicativo Win32 válido",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTinyML/tflite\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtinyML\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresultsV2.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      4\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 42\u001b[0m, in \u001b[0;36mtinyML\u001b[1;34m(model_path)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtinyML\u001b[39m(model_path):\n\u001b[1;32m---> 42\u001b[0m     gpu_delegate \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_delegate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTinyML/libtensorflowlite_gpu_delegate.so\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     interpreter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mInterpreter(model_path\u001b[38;5;241m=\u001b[39mmodel_path, experimental_delegates\u001b[38;5;241m=\u001b[39m[gpu_delegate])\n\u001b[0;32m     44\u001b[0m     interpreter\u001b[38;5;241m.\u001b[39mallocate_tensors()\n",
      "File \u001b[1;32md:\\ProjetoFeridas\\segmentacao\\image-seg-wounds\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:166\u001b[0m, in \u001b[0;36mload_delegate\u001b[1;34m(library, options)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns loaded Delegate object.\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03mExample usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m  RuntimeError: If delegate loading is used on unsupported platform.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m   delegate \u001b[38;5;241m=\u001b[39m \u001b[43mDelegate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    168\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to load delegate from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    169\u001b[0m       library, \u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32md:\\ProjetoFeridas\\segmentacao\\image-seg-wounds\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:73\u001b[0m, in \u001b[0;36mDelegate.__init__\u001b[1;34m(self, library, options)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39mpython_implementation() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPython\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     70\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDelegates are currently only supported into CPython\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     71\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdue to missing immediate reference counting.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_library \u001b[38;5;241m=\u001b[39m \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpydll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_library\u001b[38;5;241m.\u001b[39mtflite_plugin_create_delegate\u001b[38;5;241m.\u001b[39margtypes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     75\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mPOINTER(ctypes\u001b[38;5;241m.\u001b[39mc_char_p),\n\u001b[0;32m     76\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mPOINTER(ctypes\u001b[38;5;241m.\u001b[39mc_char_p), ctypes\u001b[38;5;241m.\u001b[39mc_int,\n\u001b[0;32m     77\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mCFUNCTYPE(\u001b[38;5;28;01mNone\u001b[39;00m, ctypes\u001b[38;5;241m.\u001b[39mc_char_p)\n\u001b[0;32m     78\u001b[0m ]\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# The return type is really 'TfLiteDelegate*', but 'void*' is close enough.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\ctypes\\__init__.py:460\u001b[0m, in \u001b[0;36mLibraryLoader.LoadLibrary\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadLibrary\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dlltype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\ctypes\\__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 193] %1 não é um aplicativo Win32 válido"
     ]
    }
   ],
   "source": [
    "model_path = 'TinyML/tflite'\n",
    "result = tinyML(model_path)\n",
    "with open(\"resultsV2.txt\", \"a\") as file:\n",
    "    file.write(f\"Model: {result[0]}\\n\")\n",
    "    file.write(f\"Model Size: {result[1]} MB\\n\")\n",
    "    file.write(f\"Inference Time: {result[2]} s\\n\")\n",
    "    file.write(f\"Dice Values: {result[3][0]}\\n\")\n",
    "    file.write(f\"Jaccard Value: {result[3][1]}\\n\")\n",
    "    file.write(f\"F1 Value: {result[3][2]}\\n\")\n",
    "    file.write(f\"Recall Value: {result[3][3]}\\n\")\n",
    "    file.write(f\"Precision Value: {result[3][4]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'TinyML/tflite-reduzido'\n",
    "result = tinyML(model_path)\n",
    "with open(\"resultsV2.txt\", \"a\") as file:\n",
    "    file.write(f\"Model: {result[0]}\\n\")\n",
    "    file.write(f\"Model Size: {result[1]} MB\\n\")\n",
    "    file.write(f\"Inference Time: {result[2]} s\\n\")\n",
    "    file.write(f\"Dice Value: {result[3][0]}\\n\")\n",
    "    file.write(f\"Jaccard Value: {result[3][1]}\\n\")\n",
    "    file.write(f\"F1 Value: {result[3][2]}\\n\")\n",
    "    file.write(f\"Recall Value: {result[3][3]}\\n\")\n",
    "    file.write(f\"Precision Value: {result[3][4]}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
